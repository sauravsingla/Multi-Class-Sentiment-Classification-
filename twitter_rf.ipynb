{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_rf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravsingla/Multi-Class-Sentiment-Classification-/blob/main/twitter_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ga4hMnSbBGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04c22a0-f13b-46c5-d3b8-3d1cf788f55d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBpP6W01u5L_"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras.layers import Bidirectional, GRU, GlobalMaxPool1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import time\n",
        "import nltk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from pandas import DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBSQsY__J1JB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fcd400-ffff-4eaf-ce10-fdaaa73ab4af"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/NLP/text_emotion.csv\")\n",
        "df = df.drop([\"tweet_id\",\"author\"],axis = 1)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    sentiment                                            content\n",
            "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
            "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
            "2     sadness                Funeral ceremony...gloomy friday...\n",
            "3  enthusiasm               wants to hang out with friends SOON!\n",
            "4     neutral  @dannycastillo We want to trade with someone w...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEGusFHvJ4z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be7cf75-84d2-4a70-da3e-1212f6f20c71"
      },
      "source": [
        "df.drop(df[df['sentiment'] == 'empty'].index, inplace = True)\n",
        "df.drop(df[df['sentiment'] == 'enthusiasm'].index, inplace = True)\n",
        "df['target'] = df['sentiment'].map({'sadness':0, 'boredom':1,'neutral':2,'worry':3,'surprise':4,'love':5,'fun':6,'hate':7,'happiness':8,'anger':9,'relief':10})\n",
        "df = df.drop([\"sentiment\"],axis=1)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             content  target\n",
            "1  Layin n bed with a headache  ughhhh...waitin o...       0\n",
            "2                Funeral ceremony...gloomy friday...       0\n",
            "4  @dannycastillo We want to trade with someone w...       2\n",
            "5  Re-pinging @ghostridah14: why didn't you go to...       3\n",
            "6  I should be sleep, but im not! thinking about ...       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odgQlKJsKADI"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"don't\", \"do not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"didn't\", \"did not\", text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkrnZPzFKDcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "acaaade3-e81a-4753-e114-135bc348eb85"
      },
      "source": [
        "cleaned_text = []\n",
        "for text in df['content']:\n",
        "    cleaned_text.append(clean_text(text))\n",
        "df['clean'] = cleaned_text\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "      <td>2</td>\n",
              "      <td>@dannycastillo we want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>3</td>\n",
              "      <td>re-pinging @ghostridah14: why did not you go t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>0</td>\n",
              "      <td>i should be sleep, but im not! thinking about ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...                                              clean\n",
              "1  Layin n bed with a headache  ughhhh...waitin o...  ...  layin n bed with a headache  ughhhh...waitin o...\n",
              "2                Funeral ceremony...gloomy friday...  ...                funeral ceremony...gloomy friday...\n",
              "4  @dannycastillo We want to trade with someone w...  ...  @dannycastillo we want to trade with someone w...\n",
              "5  Re-pinging @ghostridah14: why didn't you go to...  ...  re-pinging @ghostridah14: why did not you go t...\n",
              "6  I should be sleep, but im not! thinking about ...  ...  i should be sleep, but im not! thinking about ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv2xCANVKIkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e92393b7-4254-4d3d-e95b-7c4fd452882c"
      },
      "source": [
        "tw = []\n",
        "for j in df['clean']:\n",
        "  tweets = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", str(j)).split())\n",
        "  tw.append(tweets)\n",
        "df['clean'] = tw\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed with a headache ughhhh waitin on y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "      <td>2</td>\n",
              "      <td>we want to trade with someone who has houston ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>3</td>\n",
              "      <td>re pinging why did not you go to prom bc my bf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>0</td>\n",
              "      <td>i should be sleep but im not thinking about an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...                                              clean\n",
              "1  Layin n bed with a headache  ughhhh...waitin o...  ...  layin n bed with a headache ughhhh waitin on y...\n",
              "2                Funeral ceremony...gloomy friday...  ...                     funeral ceremony gloomy friday\n",
              "4  @dannycastillo We want to trade with someone w...  ...  we want to trade with someone who has houston ...\n",
              "5  Re-pinging @ghostridah14: why didn't you go to...  ...  re pinging why did not you go to prom bc my bf...\n",
              "6  I should be sleep, but im not! thinking about ...  ...  i should be sleep but im not thinking about an...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFtHpf3AKPC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2746ac4f-f00e-4a59-a86f-f7ec5b4bc07f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bYfEe0GKUoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "aa785bab-a9e5-4d24-feef-d9bad8f0c572"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "output = []\n",
        "for sentence in df[\"clean\"]:\n",
        "    temp_list = []\n",
        "    for word in sentence.split():\n",
        "      if len(word) > 2 not in stopwords:\n",
        "        temp_list.append(word)\n",
        "    output.append(' '.join(temp_list))\n",
        "    \n",
        "df[\"texts\"] = output\n",
        "df = df.drop(['content','clean'], axis = 1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>layin bed with headache ughhhh waitin your call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>want trade with someone who has houston ticket...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>pinging why did not you prom did not like friends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>should sleep but not thinking about old friend...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                              texts\n",
              "1       0    layin bed with headache ughhhh waitin your call\n",
              "2       0                     funeral ceremony gloomy friday\n",
              "4       2  want trade with someone who has houston ticket...\n",
              "5       3  pinging why did not you prom did not like friends\n",
              "6       0  should sleep but not thinking about old friend..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3rjqPYzKYkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "add45a00-dc4b-4667-e4d8-5f183e54c88f"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "\n",
        "def lemmatize_text(texts):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(texts)]\n",
        "\n",
        "\n",
        "df['text_lemmatized'] = df.texts.apply(lemmatize_text)\n",
        "\n",
        "sc = [[' '.join(i)] for i in df['text_lemmatized']]\n",
        "lis = []\n",
        "for i in sc:\n",
        "    abc = i[0]\n",
        "    lis.append(abc)\n",
        "\n",
        "df['lem'] = lis\n",
        "df = df.drop(['text_lemmatized','texts'], axis =1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>layin bed with headache ughhhh waitin your call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>want trade with someone who ha houston ticket ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>pinging why did not you prom did not like friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>should sleep but not thinking about old friend...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                                lem\n",
              "1       0    layin bed with headache ughhhh waitin your call\n",
              "2       0                     funeral ceremony gloomy friday\n",
              "4       2  want trade with someone who ha houston ticket ...\n",
              "5       3   pinging why did not you prom did not like friend\n",
              "6       0  should sleep but not thinking about old friend..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yeb195QYzhNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ebf641-a36f-4298-8f4b-c559723ac3b7"
      },
      "source": [
        "X = df[\"lem\"]\n",
        "Y = df[\"target\"]\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1          layin bed with headache ughhhh waitin your call\n",
            "2                           funeral ceremony gloomy friday\n",
            "4        want trade with someone who ha houston ticket ...\n",
            "5         pinging why did not you prom did not like friend\n",
            "6        should sleep but not thinking about old friend...\n",
            "                               ...                        \n",
            "39995                                                     \n",
            "39996                            happy mother day all love\n",
            "39997    happy mother day all the mommy out there you w...\n",
            "39998    wassup beautiful follow peep out new hit singl...\n",
            "39999    bullet train from tokyo the and have been visi...\n",
            "Name: lem, Length: 38414, dtype: object\n",
            "1        0\n",
            "2        0\n",
            "4        2\n",
            "5        3\n",
            "6        0\n",
            "        ..\n",
            "39995    2\n",
            "39996    5\n",
            "39997    5\n",
            "39998    8\n",
            "39999    5\n",
            "Name: target, Length: 38414, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtdR73MZK5Zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5349d5-dbfa-4c6a-d06e-595a6c5d8b38"
      },
      "source": [
        "## word2vec\n",
        "\n",
        "class Word2VecVectorizer:\n",
        "  def __init__(self):\n",
        "    print(\"Loading in word vectors...\")\n",
        "    self.word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/NLP/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "    print(\"Finished loading in word vectors\")\n",
        "\n",
        "  def fit(self, data):\n",
        "    pass\n",
        "\n",
        "  def transform(self, data):\n",
        "    # determine the dimensionality of vectors\n",
        "    v = self.word_vectors.get_vector('king')\n",
        "    self.D = v.shape[0]\n",
        "\n",
        "    X = np.zeros((len(data), self.D))\n",
        "    n = 0\n",
        "    emptycount = 0\n",
        "    for sentence in data:\n",
        "      tokens = sentence.split()\n",
        "      vecs = []\n",
        "      m = 0\n",
        "      for word in tokens:\n",
        "        try:\n",
        "          # throws KeyError if word not found\n",
        "          vec = self.word_vectors.get_vector(word)\n",
        "          vecs.append(vec)\n",
        "          m += 1\n",
        "        except KeyError:\n",
        "          pass\n",
        "      if len(vecs) > 0:\n",
        "        vecs = np.array(vecs)\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "      else:\n",
        "        emptycount += 1\n",
        "      n += 1\n",
        "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
        "    return X\n",
        "\n",
        "\n",
        "  def fit_transform(self, data):\n",
        "    self.fit(data)\n",
        "    return self.transform(data)\n",
        "\n",
        "vectorizer = Word2VecVectorizer()\n",
        "Xtrain = vectorizer.fit_transform(Xtrain)\n",
        "\n",
        "Xtest = vectorizer.transform(Xtest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading in word vectors...\n",
            "Finished loading in word vectors\n",
            "Numer of samples with no words found: 154 / 26889\n",
            "Numer of samples with no words found: 57 / 11525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7SGbltCLjFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f82883-aa7d-4912-f88a-fa008b3697d2"
      },
      "source": [
        "# create the model, train it, print scores\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))\n",
        "\n",
        "\n",
        "y_pred = model.predict(Xtest)\n",
        "cnfv=confusion_matrix(Ytest,y_pred)\n",
        "print(cnfv)\n",
        "\n",
        "\n",
        "print(classification_report(Ytest, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score: 0.9823719736695303\n",
            "test score: 0.34004338394793926\n",
            "[[ 122    0  424  916    2   26    0    6   64    1    0]\n",
            " [   3    0   22   25    0    0    0    0    3    0    0]\n",
            " [  39    1 1579  701    7   66    6    0  160    0    3]\n",
            " [  94    0  863 1481    0   60    0    3  104    0    4]\n",
            " [   7    0  252  268    1   25    0    1   67    0    0]\n",
            " [  26    0  342  258    3  325    2    0  216    0    0]\n",
            " [   6    0  222  186    0   12    1    0  106    0    1]\n",
            " [  18    0  122  269    0    3    0    6    9    0    0]\n",
            " [  14    0  583  389    0  120    4    0  404    0    2]\n",
            " [   1    0    9   19    0    1    0    0    4    0    0]\n",
            " [   4    0  187  166    0   15    0    0   64    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.08      0.13      1561\n",
            "           1       0.00      0.00      0.00        53\n",
            "           2       0.34      0.62      0.44      2562\n",
            "           3       0.32      0.57      0.41      2609\n",
            "           4       0.08      0.00      0.00       621\n",
            "           5       0.50      0.28      0.36      1172\n",
            "           6       0.08      0.00      0.00       534\n",
            "           7       0.38      0.01      0.03       427\n",
            "           8       0.34      0.27      0.30      1516\n",
            "           9       0.00      0.00      0.00        34\n",
            "          10       0.00      0.00      0.00       436\n",
            "\n",
            "    accuracy                           0.34     11525\n",
            "   macro avg       0.22      0.17      0.15     11525\n",
            "weighted avg       0.31      0.34      0.28     11525\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}