{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravsingla/Multi-Class-Sentiment-Classification-/blob/main/twitter_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHsYMEURZj8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4d1b3c-f096-434d-deac-a03d1fc77890"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4KRiu5AaDK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4336044e-3e48-476d-f3d8-015c8d9c7811"
      },
      "source": [
        "pip install bert-for-tf2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-r1WWqtZnU8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "from bert import bert_tokenization\n",
        "BertTokenizer = bert_tokenization.FullTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2aYB_5LZ2pD"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras.layers import Bidirectional, GRU, GlobalMaxPool1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import time\n",
        "import nltk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from pandas import DataFrame\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-25xPFKiaxqZ"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"don't\", \"do not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"didn't\", \"did not\", text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3rseTkP-bD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c455d05-d89e-4894-d7ee-5fa87652cf90"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/NLP/text_emotion.csv\")\n",
        "df = df.drop([\"tweet_id\",\"author\"],axis = 1)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    sentiment                                            content\n",
            "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
            "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
            "2     sadness                Funeral ceremony...gloomy friday...\n",
            "3  enthusiasm               wants to hang out with friends SOON!\n",
            "4     neutral  @dannycastillo We want to trade with someone w...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BfGcbYiQEdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f81e056-ffd5-40ed-ffad-7a0fb54222c6"
      },
      "source": [
        "df.drop(df[df['sentiment'] == 'empty'].index, inplace = True)\n",
        "df.drop(df[df['sentiment'] == 'enthusiasm'].index, inplace = True)\n",
        "df['target'] = df['sentiment'].map({'sadness':0, 'boredom':1,'neutral':2,'worry':3,'surprise':4,'love':5,'fun':6,'hate':7,'happiness':8,'anger':9,'relief':10})\n",
        "df = df.drop([\"sentiment\"],axis=1)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             content  target\n",
            "1  Layin n bed with a headache  ughhhh...waitin o...       0\n",
            "2                Funeral ceremony...gloomy friday...       0\n",
            "4  @dannycastillo We want to trade with someone w...       2\n",
            "5  Re-pinging @ghostridah14: why didn't you go to...       3\n",
            "6  I should be sleep, but im not! thinking about ...       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYfqRA7YbkTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d4050204-a29e-4a13-e6b4-39f9205fc6f8"
      },
      "source": [
        "cleaned_text = []\n",
        "for text in df['content']:\n",
        "    cleaned_text.append(clean_text(text))\n",
        "df['clean'] = cleaned_text\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "      <td>2</td>\n",
              "      <td>@dannycastillo we want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>3</td>\n",
              "      <td>re-pinging @ghostridah14: why did not you go t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>0</td>\n",
              "      <td>i should be sleep, but im not! thinking about ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...                                              clean\n",
              "1  Layin n bed with a headache  ughhhh...waitin o...  ...  layin n bed with a headache  ughhhh...waitin o...\n",
              "2                Funeral ceremony...gloomy friday...  ...                funeral ceremony...gloomy friday...\n",
              "4  @dannycastillo We want to trade with someone w...  ...  @dannycastillo we want to trade with someone w...\n",
              "5  Re-pinging @ghostridah14: why didn't you go to...  ...  re-pinging @ghostridah14: why did not you go t...\n",
              "6  I should be sleep, but im not! thinking about ...  ...  i should be sleep, but im not! thinking about ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8TLrtEGbrNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4f4bded1-1091-497c-cee8-70d19a9960e1"
      },
      "source": [
        "tw = []\n",
        "for j in df['clean']:\n",
        "  tweets = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", str(j)).split())\n",
        "  tw.append(tweets)\n",
        "df['clean'] = tw\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed with a headache ughhhh waitin on y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "      <td>2</td>\n",
              "      <td>we want to trade with someone who has houston ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>3</td>\n",
              "      <td>re pinging why did not you go to prom bc my bf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>0</td>\n",
              "      <td>i should be sleep but im not thinking about an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...                                              clean\n",
              "1  Layin n bed with a headache  ughhhh...waitin o...  ...  layin n bed with a headache ughhhh waitin on y...\n",
              "2                Funeral ceremony...gloomy friday...  ...                     funeral ceremony gloomy friday\n",
              "4  @dannycastillo We want to trade with someone w...  ...  we want to trade with someone who has houston ...\n",
              "5  Re-pinging @ghostridah14: why didn't you go to...  ...  re pinging why did not you go to prom bc my bf...\n",
              "6  I should be sleep, but im not! thinking about ...  ...  i should be sleep but im not thinking about an...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_1fFRwQeGBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18562b5-95d8-4db5-8a18-523c29908420"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "output = []\n",
        "for sentence in df[\"clean\"]:\n",
        "    temp_list = []\n",
        "    for word in sentence.split():\n",
        "      if len(word) > 2 not in stopwords:\n",
        "        temp_list.append(word)\n",
        "    output.append(' '.join(temp_list))\n",
        "    \n",
        "df[\"texts\"] = output\n",
        "df = df.drop(['content','clean'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muBIlPogeWP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "09a9e5eb-29b6-4853-e817-7d1e06a3aba9"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "\n",
        "def lemmatize_text(texts):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(texts)]\n",
        "\n",
        "\n",
        "df['text_lemmatized'] = df.texts.apply(lemmatize_text)\n",
        "\n",
        "sc = [[' '.join(i)] for i in df['text_lemmatized']]\n",
        "lis = []\n",
        "for i in sc:\n",
        "    abc = i[0]\n",
        "    lis.append(abc)\n",
        "\n",
        "df['lem'] = lis\n",
        "df = df.drop(['text_lemmatized','texts'], axis =1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>layin bed with headache ughhhh waitin your call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>want trade with someone who ha houston ticket ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>pinging why did not you prom did not like friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>should sleep but not thinking about old friend...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                                lem\n",
              "1       0    layin bed with headache ughhhh waitin your call\n",
              "2       0                     funeral ceremony gloomy friday\n",
              "4       2  want trade with someone who ha houston ticket ...\n",
              "5       3   pinging why did not you prom did not like friend\n",
              "6       0  should sleep but not thinking about old friend..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6wP4xeceaY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403c729e-f98c-4e33-9f1f-3c0b9bff73c9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "X = df[\"lem\"]\n",
        "Y = df[\"target\"]\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y, test_size = 0.30)\n",
        "Yt = np_utils.to_categorical(Ytrain)\n",
        "Yt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEbVMJF9Pilk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "78715565-0470-4af5-dfdc-f9e1b900291f"
      },
      "source": [
        "dft=pd.DataFrame(data=Yt[0:,0:],index=[i for i in range(Yt.shape[0])],columns=['f'+str(i) for i in range(Yt.shape[1])])\n",
        "dft.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f0</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    f0   f1   f2   f3   f4   f5   f6   f7   f8   f9  f10\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
              "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkeuiaVee_I"
      },
      "source": [
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poAN4qJPes7n"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=40):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)      \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYJtixjyfQhV"
      },
      "source": [
        "def build_model(bert_layer, max_len=44):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(11, activation='softmax')(clf_output)\n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHqzEt_jfcUy"
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz4DKWCdfrXp"
      },
      "source": [
        "# train_input = bert_encode(df..values, tokenizer, max_len=20)\n",
        "# test_input = bert_encode(df2.content.values, tokenizer, max_len=20)\n",
        "# train_labels = df1.target.values\n",
        "train_input = bert_encode(Xtrain, tokenizer, max_len=40)\n",
        "test_input = bert_encode(Xtest, tokenizer, max_len=40)\n",
        "train_labels = dft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Aq-oKkgSlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd80f65-d573-4470-d10f-9ccfedec3405"
      },
      "source": [
        "model = build_model(bert_layer, max_len=40)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 1024)]       0           keras_layer_2[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 11)           11275       tf_op_layer_strided_slice_2[0][0]\n",
            "==================================================================================================\n",
            "Total params: 335,153,164\n",
            "Trainable params: 335,153,163\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNFYsn6egrF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdfcb9e-8a87-4ebc-b748-06e5b20e98e3"
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    epochs=3,\n",
        "    batch_size=32,\n",
        "    validation_split=0.4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "505/505 [==============================] - 522s 1s/step - loss: 1.8025 - accuracy: 0.3563 - val_loss: 1.7002 - val_accuracy: 0.3944\n",
            "Epoch 2/3\n",
            "414/505 [=======================>......] - ETA: 1:16 - loss: 1.5584 - accuracy: 0.4482"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbJxtj1og9M5"
      },
      "source": [
        "test_pred = model.predict(test_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ZOgH1UTntY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_history.history['loss'], label='loss')\n",
        "plt.plot(train_history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(train_history.history['accuracy'], label='acc')\n",
        "plt.plot(train_history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbu_0XPzTwqW"
      },
      "source": [
        "p = np.argmax(test_pred, axis=1)\n",
        "print(p)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cnfv=confusion_matrix(Ytest,p)\n",
        "print(cnfv)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Ytest, p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYsznPG-T61z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}